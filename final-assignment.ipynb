{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51655f1c-23d9-45d0-9dd9-16afa391f778",
   "metadata": {},
   "source": [
    "# Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af143faf",
   "metadata": {},
   "source": [
    "The intention of [Textplumber](https://geoffford.nz/textplumber/) is to make it easy to extract features from text data as part of a Sci-kit learn pipeline. It allows you to extract different kinds of features extracted from text, which you can combine as needed. This example demonstrates functionality using different datasets. If you are accessing this example from the [documentation site](https://geoffford.nz/textplumber/), you can [download the notebook from Github](https://github.com/polsci/textplumber/blob/main/nbs/example.ipynb).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9585e",
   "metadata": {},
   "source": [
    "You can install Textplumber using pip ...\n",
    "\n",
    "\tpip install textplumber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b31b2a",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87237ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Note: the directive above is used to prevent the code being executed during release.\n",
    "# If you have downloaded the notebook for your own use, you can remove the directive,\n",
    "# but this is not necessary (it is just a comment).\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from textplumber.core import *\n",
    "from textplumber.clean import *\n",
    "from textplumber.preprocess import *\n",
    "from textplumber.tokens import *\n",
    "from textplumber.pos import *\n",
    "from textplumber.embeddings import *\n",
    "from textplumber.report import *\n",
    "from textplumber.store import *\n",
    "from textplumber.lexicons import *\n",
    "from textplumber.textstats import *\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9588bdd",
   "metadata": {},
   "source": [
    "These settings control the display of Pandas dataframes in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "pd.set_option('display.max_columns', None) # show all columns\n",
    "pd.set_option('display.max_colwidth', 500) # increase this to see more text in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d47a58",
   "metadata": {},
   "source": [
    "Get word lists: \n",
    "* The stop word list is from NLTK.   \n",
    "* All of the word lists (including the stop word list) can be used to extract lexicon count features to extract features based on a set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce00426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "stop_words = get_stop_words()\n",
    "stop_words_lexicon = {'stop_words': stop_words}\n",
    "empath_lexicons = get_empath_lexicons()\n",
    "vader_lexicons = get_sentiment_lexicons()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e1848-5064-46dc-b8fb-a90e41ead2c5",
   "metadata": {},
   "source": [
    "## 2. Load and inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a182a",
   "metadata": {},
   "source": [
    "### 2.1 Choose a dataset and preview the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd33c2",
   "metadata": {},
   "source": [
    "Below you can select a dataset. The options are `sentiment`, `clickbait`, `essay` and `movie_reviews`. Change the value of `dataset_option` below. The datasets (available on Huggingface) will be downloaded automatically and a link provided to the dataset card with more information.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe2bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected the movie_reviews dataset. Read more about this at https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dataset_option = 'movie_reviews' # 'essay', 'sentiment', 'clickbait', 'essay, or 'movie_reviews'\n",
    "\n",
    "if dataset_option == 'sentiment':\n",
    "\tdataset_name = 'cardiffnlp/tweet_eval'\n",
    "\tdataset_dir = 'sentiment'\n",
    "\ttarget_labels = ['negative', 'neutral', 'positive']\n",
    "\ttext_column = 'text'\n",
    "\tlabel_column = 'label'\n",
    "\ttrain_split_name = 'train'\n",
    "\ttest_split_name = 'validation'\n",
    "\tprint('You selected the sentiment dataset. Read more about this at https://huggingface.co/datasets/cardiffnlp/tweet_eval')\n",
    "elif dataset_option == 'clickbait':\n",
    "\tdataset_name = 'christinacdl/clickbait_detection_dataset'\n",
    "\tdataset_dir = None\n",
    "\ttarget_labels = ['CLICKBAIT', 'NOT']\n",
    "\ttext_column = 'text'\n",
    "\tlabel_column = 'label'\n",
    "\ttrain_split_name = 'train'\n",
    "\ttest_split_name = 'validation'\n",
    "\tprint('You selected the clickbait dataset. Read more about this at https://huggingface.co/datasets/christinacdl/clickbait_detection_dataset')\n",
    "elif dataset_option == 'essay':\n",
    "\tdataset_name = 'polsci/ghostbuster-essay-cleaned'\n",
    "\tdataset_dir = None\n",
    "\ttarget_labels = ['claude', 'gpt', 'human']\n",
    "\ttext_column = 'text'\n",
    "\tlabel_column = 'label'\n",
    "\ttrain_split_name = 'train'\n",
    "\ttest_split_name = 'test'\n",
    "\tprint('You selected the essay dataset. Read more about this at https://huggingface.co/datasets/polsci/ghostbuster-essay-cleaned')\n",
    "else:\n",
    "\tdataset_name = 'polsci/sentiment-polarity-dataset-v2.0'\n",
    "\tdataset_dir = None\n",
    "\ttarget_labels = ['neg', 'pos']\n",
    "\ttext_column = 'text'\n",
    "\tlabel_column = 'label'\n",
    "\ttrain_split_name = 'train'\n",
    "\ttest_split_name = 'train'\n",
    "\tprint('You selected the movie_reviews dataset. Read more about this at https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04f51e",
   "metadata": {},
   "source": [
    "Make sure you go to the link above to read more about the selected dataset.\n",
    "\n",
    "#### Important notes about specific datasets:\n",
    "\n",
    "* For the *sentiment* dataset, it is challenging to get good accuracy with three classes. If you like you can remove the `neutral` class. There is a cell below that does this for you - don't change the cell above.\n",
    "* For the *essay* dataset, there are differences in punctuation between classes. To avoid fitting to a quirk of the data, you can replace characters via the `TextCleaner` component like this:  \n",
    "```\n",
    "TextCleaner(strip_whitespace=True, character_replacements = {\"’\": \"'\", '“': '\"', '”': '\"'})\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2541b71",
   "metadata": {},
   "source": [
    "This loads the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39078bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dataset = load_dataset(dataset_name, data_dir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdffe84",
   "metadata": {},
   "source": [
    "This cell will show you information on the dataset fields and splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a48d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t<style>\n",
       "\tdetails {\n",
       "\t\tbackground:#f0f0f0;\n",
       "\t\tcolor:#000;\n",
       "\t\tborder-radius: 0.5em; \n",
       "\t\tpadding: 0;\n",
       "\t\tmargin-bottom:1em;\n",
       "\t\tborder: 1px solid #ccc;\n",
       "\t\twidth: auto;\n",
       "        font-size: 0.9em;\n",
       "        overflow-wrap: break-word;\n",
       "\t}\n",
       "\t\t\t\n",
       "\tdetails summary {\n",
       "\t\tcursor: pointer;\n",
       "\t\tfont-weight: bold;\n",
       "\t\tfont-size: 1em;\n",
       "\t\tpadding: 1em;\n",
       "\t\tcolor: #666;\n",
       "\t}\n",
       "\n",
       "\tdetails.warnings {\n",
       "\t\tbackground-color: #f8d7da;\n",
       "\t}\n",
       "\t\t\t\n",
       "\tdetails.notices {\n",
       "\t\tbackground-color: #d4edda;\n",
       "\t}\n",
       "\n",
       "\tdetails[open] summary {\n",
       "\t\tcolor: black;\n",
       "\t\tmargin-bottom: 1em;\n",
       "\t}\n",
       "\tdetails ul, details p {\n",
       "\t\tmargin-left: 1em;\n",
       "\t}\n",
       "\tdetails pre {\n",
       "\t\tbackground-color: #f0f0f0;\n",
       "\t\toverflow: auto;\n",
       "\t}\n",
       "\tdetails h4, .featureunion > h4 {\n",
       "\t\tmargin: 0;\n",
       "\t\tmargin-left: 1em;\n",
       "\t\tpadding: 0;\n",
       "\t\tfont-size: 1em;\n",
       "\t}\n",
       "\n",
       "\t.featureunion > h4 {\n",
       "\tmargin: 1em;\n",
       "\t}\n",
       "\n",
       "\tdetails {\n",
       "\twidth: 100%;\n",
       "\t}\n",
       "\n",
       "\t.featureunion {\n",
       "\twidth:100%;\n",
       "\tborder: 1px dashed #ccc;\n",
       "\tborder-radius: 0.5em; \n",
       "\tmargin-bottom:1em;\n",
       "\t}\n",
       "\n",
       "\t.featureunion-column {\n",
       "\tfloat: left;\n",
       "\tmargin: 0.5%;\n",
       "\t}\n",
       "\n",
       "\t.featureunion::after {\n",
       "\tcontent: '';\n",
       "\tdisplay: table;\n",
       "\tclear: both;\n",
       "\t}\t\t\n",
       "\t</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<details>\n",
       "\t\t<summary>Split: train (2000 samples)</summary>\n",
       "\t\t<p>Available fields: text, label, fileid</p><ul><li>Field 'text' has 2000 unique values<pre>Value(dtype='string', id=None)</pre><li>Field 'label' has 2 unique values<pre>ClassLabel(names=['neg', 'pos'], id=None)</pre><li>Field 'fileid' has 2000 unique values<pre>Value(dtype='string', id=None)</pre></ul>\n",
       "\t\t</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<details class=\"notices\">\n",
       "\t\t<summary>Notices</summary>\n",
       "\t\t<ul><li>Field 'text' appears to be a text column.</li><li>Field 'label' is a label column (ClassLabel).</li><li>Field 'fileid' appears to be a text column.</li></ul>\n",
       "\t\t</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "preview_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93201bd6",
   "metadata": {},
   "source": [
    "This cell will cast the label column to a ClassLabel type if it isn't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'label' is already a ClassLabel.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "cast_column_to_label(dataset, label_column)\n",
    "label_names = get_label_names(dataset, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07bd82",
   "metadata": {},
   "source": [
    "Here is the breakdown of the composition of labels in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0d89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_name  count\n",
       "label                  \n",
       "0            neg   1000\n",
       "1            pos   1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Note: in future this example will be updated to use `preview_split_by_label_column`\n",
    "dfs = {}\n",
    "for split in dataset.keys():\n",
    "    dfs[split] = dataset[split].to_pandas()\n",
    "    dfs[split].insert(1, 'label_name', dfs[split][label_column].apply(lambda x: dataset[split].features[label_column].int2str(x)))\n",
    "    preview_label_counts(dfs[split], label_column, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d36f79",
   "metadata": {},
   "source": [
    "### 2.2 Configure the labels (optional)\n",
    "\n",
    "* You can override the default labels for the data-set here to make the task more or less challenging. High accuracy does not guarantee a high grade. \n",
    "* See the assignment instructions and the dataset card or corresponding paper for explanations of the data.  \n",
    "* Read the comments below and uncomment the relevant lines for your data-set if and amend the label names if needed.\n",
    "* Remember, this is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f500de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# for the movie reviews dataset (this is just for testing/demonstration) - there are 2 labels and that is it!\n",
    "\n",
    "# for the sentiment dataset - there are 3 labels - you can make the task simpler as a binary classification problem using one of these options:\n",
    "#target_labels = ['negative', 'neutral']\n",
    "#target_labels = ['negative', 'positive']\n",
    "#target_labels = ['neutral', 'positive']\n",
    "\n",
    "# for the clickbait dataset there are only 2 labels - so it is already a binary classification problem\n",
    "\n",
    "# for the essay dataset - there are 7 labels - you can make the task simpler as a binary classification problem using one of these options:\n",
    "#target_labels = ['claude', 'gpt']\n",
    "#target_labels = ['human', 'gpt'] \n",
    "#target_labels = ['human', 'claude']\n",
    "\n",
    "# for the genre dataset ... TODO\n",
    "\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a7d92",
   "metadata": {},
   "source": [
    "### 2.3 Prepare the train and test splits\n",
    "\n",
    "* This cell handles the train-test split for you.\n",
    "* Some of the data-sets are unbalanced. This cell will balance the data-sets using under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ff72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1600 samples, 2 classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_name  count\n",
       "0                  \n",
       "0        neg    800\n",
       "1        pos    800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 400 samples, 2 classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_name  count\n",
       "0                  \n",
       "0        neg    200\n",
       "1        pos    200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "target_classes = [label_names.index(name) for name in target_labels]\n",
    "target_names = [label_names[i] for i in target_classes]\n",
    "\n",
    "if train_split_name == test_split_name:\n",
    "    X = dataset[train_split_name].to_pandas()\n",
    "    X.insert(1, 'label_name', dfs[train_split_name][label_column].apply(lambda x: dataset[train_split_name].features[label_column].int2str(x)))\n",
    "    y = np.array(dataset[train_split_name][label_column])\n",
    "\n",
    "    mask = np.isin(y, target_classes)\n",
    "    X = X.loc[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # creating df splits with original data first  - so can look at the train data if needed\n",
    "    dfs['train'], dfs['test'], y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # we're just using the text for features\n",
    "    X_train = np.array(dfs['train'][text_column])\n",
    "    X_test = np.array(dfs['test'][text_column])\n",
    "else:\n",
    "    X_train = np.array(dataset[train_split_name][text_column])\n",
    "    y_train = np.array(dataset[train_split_name][label_column])\n",
    "    X_test = np.array(dataset[test_split_name][text_column])\n",
    "    y_test = np.array(dataset[test_split_name][label_column])\n",
    "\n",
    "    mask = np.isin(y_train, target_classes)\n",
    "    mask_test = np.isin(y_test, target_classes)\n",
    "\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    X_test = X_test[mask_test]\n",
    "    y_test = y_test[mask_test]\n",
    "\n",
    "# this cell undersamples all but the minority class to balance the training data\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_train, y_train = RandomUnderSampler(random_state=0).fit_resample(X_train, y_train)\n",
    "X_train = X_train.reshape(-1)\n",
    "\n",
    "preview_splits(X_train, y_train, X_test, y_test, target_classes = target_classes, target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d3de0",
   "metadata": {},
   "source": [
    "### 2.4 Preview the texts\n",
    "\n",
    "Time to get to know your data. We will only preview the train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0cee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "      <th>fileid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' first feature-length , fully-animated attempt to steal clout from disney's cartoon empire , but the mouse has no reason to be worried . \\nthe only other recent challenger to their throne was last fall's promising , if flawed , 20th century fox production \" anastasia , \" but disney's \" hercules , \" with its lively cast and colorful palate , had her beat hands-down when it came time to crown 1997's best piece of animation . \\nthis year , it's no contes...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>cv003_12683.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>rated : r for strong language , sexual dialogue , drug use , crude humor , violence and brief nudity . \\nstarring : ben affleck , matt damon , linda fiorentino , salma hayek , alan rickman , chris rock , kevin smith , jason mewes , jason lee , george carlin , alanis morissette . \\nrunning time : 130 minutes \\nbeing a huge fan of kevin smith , i was expecting a lot out of his newest project 'dogma' . \\nit might just be kevin's best work to date . \\nit's very funny with smart and foul-mouthed ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv475_21692.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>if you're the type of person who goes on the submarine ride every time you visit disneyland , you're going to love the hunt for red october . \\nyou'll also love the film if you enjoy cat and mouse military tactics , or if you're a sean connery or alec baldwin fan , or if you admired director john mctiernan's earlier films , die hard and predator . \\nin fact , the only people likely to be disappointed with the hunt for red october are those who have read the book , since films almost never li...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv452_5088.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>after 1993's \" falling down , \" i hoped that joel schumacher would mature into a great director . \\nsince then he has offered us two so-so adaptations of john grisham novels ( \" the client \" and \" a time to kill \" ) and two batman movies that lowered the standards of that franchise . \\nalthough these disappointments dampened my enthusiasm for schumacher's potential , the publicity for his latest release , \" 8mm , \" raised new hope . \\nit promised to be something unusual . \\nit wasn't . \\nthe...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>cv704_17622.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>it might surprise some to know that joel and ethan coen , who have brought such unabated lunacy to our movie screens as \" raising arizona \" and \" the hudsucker proxy , \" made their feature film debut with \" blood simple , \" a grim and often gruesome tale of revenge , murder , and literally fatal misconceptions in rural texas . \\nit bears some resemblance , story-wise , to the coens' recent \" fargo , \" but even the darkly satirical humor and the enjoyably quirky characterizations that charact...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv651_10492.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>meet joe black ( reviewed on nov . 27/98 ) \\nstarring brad pitt , anthony hopkins , claire forlani \\nin \" meet joe black \" , brad pitt plays death . \\nthat's all that really needs to be said , but nevertheless , i will provide the three of you that have seemingly been living in a cave with a plot description . \\ndeath decides to take a holiday , what with all the rigors of soul-collecting and all , and forces anthony hopkins into showing him what it's like to be human . \\ndeath assumes the b...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv098_15435.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>plot : a bunch of bad guys dressed up as elvis impersonators rob a vegas casino during a presley convention . \\nthe boys eventually get together to split the money , but as plans change , double-crosses occur , dealing and wheeling goes down and the crew set up for the road . \\nwho's on the up and up , who's the real bad guy and who's gonna get to bang courteney cox are just a few of the questions which will be answered by the rest of this movie . \\ncritique : the funnest movie that i've see...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv110_27788.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>the best thing about , \" lake placid \" is that it's only 80 minutes long and when it's over you're glad that you didn't waste more than an hour and a half of your time . \\nit's nothing more than a bad rip-off of , \" jaws \" ( and i think that's being kind . ) \\nit was written by david e . kelly ( \" ally mcbeal \" ) as a horror-comedy but fails at both , miserably . \\ni was never scared and i think that i only laughed once . \\nthe crocodile even fails in comparison to the snake in , \" anaconda ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>cv827_19479.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>it is with hesitance that i call \" apocalypse now \" a masterpiece . \\ncertainly , it had the pedigree to be one of the greatest films ever made , with a director known for producing masterpieces with ease , and some of the finest actors of the 1970's . \\nthe plot , an adaptation of joseph conrad's \" heart of darkness \" , was set in vietnam , and the timing of the film was supposed to be brilliant , coming on the heels of the end of the war . \\n \" apocalypse \" certainly has its moments , some...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv859_14107.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>here's a word analogy : amistad is to the lost world as schindler's list is to jurassic park . \\nin 1993 , after steven spielberg made the monster dino hit , many critics described schindler's list as the director's \" penance \" ( as if there was a need for him to apologize for making a crowd-pleasing blockbuster ) . \\nnow , after a three-year layoff , spielberg is back with a vengeance . \\nonce again , his summer release was special effects-loaded action/adventure flick with dinosaurs munchi...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>cv738_10116.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "3      \" quest for camelot \" is warner bros . ' first feature-length , fully-animated attempt to steal clout from disney's cartoon empire , but the mouse has no reason to be worried . \\nthe only other recent challenger to their throne was last fall's promising , if flawed , 20th century fox production \" anastasia , \" but disney's \" hercules , \" with its lively cast and colorful palate , had her beat hands-down when it came time to crown 1997's best piece of animation . \\nthis year , it's no contes...   \n",
       "1475  rated : r for strong language , sexual dialogue , drug use , crude humor , violence and brief nudity . \\nstarring : ben affleck , matt damon , linda fiorentino , salma hayek , alan rickman , chris rock , kevin smith , jason mewes , jason lee , george carlin , alanis morissette . \\nrunning time : 130 minutes \\nbeing a huge fan of kevin smith , i was expecting a lot out of his newest project 'dogma' . \\nit might just be kevin's best work to date . \\nit's very funny with smart and foul-mouthed ...   \n",
       "1452  if you're the type of person who goes on the submarine ride every time you visit disneyland , you're going to love the hunt for red october . \\nyou'll also love the film if you enjoy cat and mouse military tactics , or if you're a sean connery or alec baldwin fan , or if you admired director john mctiernan's earlier films , die hard and predator . \\nin fact , the only people likely to be disappointed with the hunt for red october are those who have read the book , since films almost never li...   \n",
       "704   after 1993's \" falling down , \" i hoped that joel schumacher would mature into a great director . \\nsince then he has offered us two so-so adaptations of john grisham novels ( \" the client \" and \" a time to kill \" ) and two batman movies that lowered the standards of that franchise . \\nalthough these disappointments dampened my enthusiasm for schumacher's potential , the publicity for his latest release , \" 8mm , \" raised new hope . \\nit promised to be something unusual . \\nit wasn't . \\nthe...   \n",
       "1651  it might surprise some to know that joel and ethan coen , who have brought such unabated lunacy to our movie screens as \" raising arizona \" and \" the hudsucker proxy , \" made their feature film debut with \" blood simple , \" a grim and often gruesome tale of revenge , murder , and literally fatal misconceptions in rural texas . \\nit bears some resemblance , story-wise , to the coens' recent \" fargo , \" but even the darkly satirical humor and the enjoyably quirky characterizations that charact...   \n",
       "1098  meet joe black ( reviewed on nov . 27/98 ) \\nstarring brad pitt , anthony hopkins , claire forlani \\nin \" meet joe black \" , brad pitt plays death . \\nthat's all that really needs to be said , but nevertheless , i will provide the three of you that have seemingly been living in a cave with a plot description . \\ndeath decides to take a holiday , what with all the rigors of soul-collecting and all , and forces anthony hopkins into showing him what it's like to be human . \\ndeath assumes the b...   \n",
       "1110  plot : a bunch of bad guys dressed up as elvis impersonators rob a vegas casino during a presley convention . \\nthe boys eventually get together to split the money , but as plans change , double-crosses occur , dealing and wheeling goes down and the crew set up for the road . \\nwho's on the up and up , who's the real bad guy and who's gonna get to bang courteney cox are just a few of the questions which will be answered by the rest of this movie . \\ncritique : the funnest movie that i've see...   \n",
       "827   the best thing about , \" lake placid \" is that it's only 80 minutes long and when it's over you're glad that you didn't waste more than an hour and a half of your time . \\nit's nothing more than a bad rip-off of , \" jaws \" ( and i think that's being kind . ) \\nit was written by david e . kelly ( \" ally mcbeal \" ) as a horror-comedy but fails at both , miserably . \\ni was never scared and i think that i only laughed once . \\nthe crocodile even fails in comparison to the snake in , \" anaconda ...   \n",
       "1859  it is with hesitance that i call \" apocalypse now \" a masterpiece . \\ncertainly , it had the pedigree to be one of the greatest films ever made , with a director known for producing masterpieces with ease , and some of the finest actors of the 1970's . \\nthe plot , an adaptation of joseph conrad's \" heart of darkness \" , was set in vietnam , and the timing of the film was supposed to be brilliant , coming on the heels of the end of the war . \\n \" apocalypse \" certainly has its moments , some...   \n",
       "1738  here's a word analogy : amistad is to the lost world as schindler's list is to jurassic park . \\nin 1993 , after steven spielberg made the monster dino hit , many critics described schindler's list as the director's \" penance \" ( as if there was a need for him to apologize for making a crowd-pleasing blockbuster ) . \\nnow , after a three-year layoff , spielberg is back with a vengeance . \\nonce again , his summer release was special effects-loaded action/adventure flick with dinosaurs munchi...   \n",
       "\n",
       "     label_name  label           fileid  \n",
       "3           neg      0  cv003_12683.txt  \n",
       "1475        pos      1  cv475_21692.txt  \n",
       "1452        pos      1   cv452_5088.txt  \n",
       "704         neg      0  cv704_17622.txt  \n",
       "1651        pos      1  cv651_10492.txt  \n",
       "1098        pos      1  cv098_15435.txt  \n",
       "1110        pos      1  cv110_27788.txt  \n",
       "827         neg      0  cv827_19479.txt  \n",
       "1859        pos      1  cv859_14107.txt  \n",
       "1738        pos      1  cv738_10116.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "y_train_names = map(lambda x: label_names[x], y_train)\n",
    "display(dfs['train'].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba8b2b0",
   "metadata": {},
   "source": [
    "Enter the index (the number in the first column) as `selected_index` to see the row. The `limit` value controls how much of the text you see. Set a higher limit to see more of the text or set it to 0 to see all of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30583aef-080f-427a-b883-6a7c7f633dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label_name</th>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fileid</th>\n",
       "      <td>cv010_29063.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Attribute                  \n",
       "label_name              neg\n",
       "label                     0\n",
       "fileid      cv010_29063.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:\n",
      "best remembered for his understated performance as dr . hannibal lecter in\n",
      "michael mann's forensics thriller , manhunter , scottish character actor brian\n",
      "cox brings something special to every movie he works on .  usually playing a bit\n",
      "role in some studio schlock ( he dies halfway through the long kiss goodnight )\n",
      ", he's only occasionally given something meaty and substantial to do .  if you\n",
      "want t...\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# We can display the full text of a selected article by dataframe index\n",
    "selected_index = 10\n",
    "\n",
    "preview_row_text(dfs['train'], selected_index, text_column = text_column, limit=400) # change limit to see more of the text if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca47acd",
   "metadata": {},
   "source": [
    "## 3. Create a classification pipeline and train a model\n",
    "\n",
    "Create a Sci-kit Learn pipeline to preprocess the texts and train a classification model. The pipeline components will be added in through the notebook. There are a number of pipeline components you can access through the `textplumber` package. You will have an opportunity to learn about this in labs, but documentation is [available here](https://geoffford.nz/textplumber)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe248aaa",
   "metadata": {},
   "source": [
    "To speed up preprocessing some of the pipeline components store the preprocessed data in a cache to avoid recomputing them. Run this as is - it will create an SQLite file with the name of your dataset option in the directory of the notebook. This will speed up some repeated processing (e.g. tokenization with Spacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285160e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "feature_store = TextFeatureStore(f'example-{dataset_option}.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a558f6d",
   "metadata": {},
   "source": [
    "The pipeline below includes a number of different components. Most are commented out on the first run of the notebook. There are lots of options for each component. You can look at [the documentation](https://geoffford.nz/textplumber) to learn about these. These components can extract different kinds of features, any of which can be applied to build a model. The potential feature types include:\n",
    "\n",
    "* Token features  \n",
    "* Bigram features  \n",
    "* Parts of speech features\n",
    "* Lexicon-based features  \n",
    "* Document-level statistics  \n",
    "* Text embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0567b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, TextCleaner(strip_whitespace=True)),\n",
       "                (&#x27;spacy&#x27;,\n",
       "                 SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)),\n",
       "                (&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                                  TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                                               &quot;&#x27;ll&quot;,\n",
       "                                                                                               &quot;&#x27;m&quot;,\n",
       "                                                                                               &quot;&#x27;re&quot;,\n",
       "                                                                                               &quot;&#x27;s&quot;,\n",
       "                                                                                               &quot;&#x27;ve&quot;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;about&#x27;,\n",
       "                                                                                               &#x27;above&#x27;,\n",
       "                                                                                               &#x27;after&#x27;,\n",
       "                                                                                               &#x27;again&#x27;,\n",
       "                                                                                               &#x27;against&#x27;,\n",
       "                                                                                               &#x27;ain&#x27;,\n",
       "                                                                                               &#x27;all&#x27;,\n",
       "                                                                                               &#x27;am&#x27;,\n",
       "                                                                                               &#x27;an&#x27;,\n",
       "                                                                                               &#x27;and&#x27;,\n",
       "                                                                                               &#x27;any&#x27;,\n",
       "                                                                                               &#x27;are&#x27;,\n",
       "                                                                                               &#x27;aren&#x27;,\n",
       "                                                                                               &#x27;as&#x27;,\n",
       "                                                                                               &#x27;at&#x27;,\n",
       "                                                                                               &#x27;be&#x27;,\n",
       "                                                                                               &#x27;because&#x27;,\n",
       "                                                                                               &#x27;been&#x27;,\n",
       "                                                                                               &#x27;before&#x27;,\n",
       "                                                                                               &#x27;being&#x27;,\n",
       "                                                                                               &#x27;below&#x27;,\n",
       "                                                                                               &#x27;between&#x27;,\n",
       "                                                                                               &#x27;both&#x27;, ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, TextCleaner(strip_whitespace=True)),\n",
       "                (&#x27;spacy&#x27;,\n",
       "                 SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)),\n",
       "                (&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                                  TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                                               &quot;&#x27;ll&quot;,\n",
       "                                                                                               &quot;&#x27;m&quot;,\n",
       "                                                                                               &quot;&#x27;re&quot;,\n",
       "                                                                                               &quot;&#x27;s&quot;,\n",
       "                                                                                               &quot;&#x27;ve&quot;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;about&#x27;,\n",
       "                                                                                               &#x27;above&#x27;,\n",
       "                                                                                               &#x27;after&#x27;,\n",
       "                                                                                               &#x27;again&#x27;,\n",
       "                                                                                               &#x27;against&#x27;,\n",
       "                                                                                               &#x27;ain&#x27;,\n",
       "                                                                                               &#x27;all&#x27;,\n",
       "                                                                                               &#x27;am&#x27;,\n",
       "                                                                                               &#x27;an&#x27;,\n",
       "                                                                                               &#x27;and&#x27;,\n",
       "                                                                                               &#x27;any&#x27;,\n",
       "                                                                                               &#x27;are&#x27;,\n",
       "                                                                                               &#x27;aren&#x27;,\n",
       "                                                                                               &#x27;as&#x27;,\n",
       "                                                                                               &#x27;at&#x27;,\n",
       "                                                                                               &#x27;be&#x27;,\n",
       "                                                                                               &#x27;because&#x27;,\n",
       "                                                                                               &#x27;been&#x27;,\n",
       "                                                                                               &#x27;before&#x27;,\n",
       "                                                                                               &#x27;being&#x27;,\n",
       "                                                                                               &#x27;below&#x27;,\n",
       "                                                                                               &#x27;between&#x27;,\n",
       "                                                                                               &#x27;both&#x27;, ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>TextCleaner</div></div></label><div class=\"sk-toggleable__content \"><pre>TextCleaner(strip_whitespace=True)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SpacyPreprocessor</div></div></label><div class=\"sk-toggleable__content \"><pre>SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>features: FeatureUnion</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.FeatureUnion.html\">?<span>Documentation for features: FeatureUnion</span></a></div></label><div class=\"sk-toggleable__content \"><pre>FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                 TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,\n",
       "                                                                  lowercase=True,\n",
       "                                                                  max_features=100,\n",
       "                                                                  min_df=0.0,\n",
       "                                                                  remove_punctuation=True,\n",
       "                                                                  stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                              &quot;&#x27;ll&quot;,\n",
       "                                                                              &quot;&#x27;m&quot;,\n",
       "                                                                              &quot;&#x27;re&quot;,\n",
       "                                                                              &quot;&#x27;s&quot;,\n",
       "                                                                              &quot;&#x27;ve&quot;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;about&#x27;,\n",
       "                                                                              &#x27;above&#x27;,\n",
       "                                                                              &#x27;after&#x27;,\n",
       "                                                                              &#x27;again&#x27;,\n",
       "                                                                              &#x27;against&#x27;,\n",
       "                                                                              &#x27;ain&#x27;,\n",
       "                                                                              &#x27;all&#x27;,\n",
       "                                                                              &#x27;am&#x27;,\n",
       "                                                                              &#x27;an&#x27;,\n",
       "                                                                              &#x27;and&#x27;,\n",
       "                                                                              &#x27;any&#x27;,\n",
       "                                                                              &#x27;are&#x27;,\n",
       "                                                                              &#x27;aren&#x27;,\n",
       "                                                                              &#x27;as&#x27;,\n",
       "                                                                              &#x27;at&#x27;,\n",
       "                                                                              &#x27;be&#x27;,\n",
       "                                                                              &#x27;because&#x27;,\n",
       "                                                                              &#x27;been&#x27;,\n",
       "                                                                              &#x27;before&#x27;,\n",
       "                                                                              &#x27;being&#x27;,\n",
       "                                                                              &#x27;below&#x27;,\n",
       "                                                                              &#x27;between&#x27;,\n",
       "                                                                              &#x27;both&#x27;, ...]))],\n",
       "                                         verbose=True))],\n",
       "             verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><label>tokens</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>TokensVectorizer</div></div></label><div class=\"sk-toggleable__content \"><pre>TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,\n",
       "                 lowercase=True, max_features=100, min_df=0.0,\n",
       "                 remove_punctuation=True,\n",
       "                 stop_words=[&quot;&#x27;d&quot;, &quot;&#x27;ll&quot;, &quot;&#x27;m&quot;, &quot;&#x27;re&quot;, &quot;&#x27;s&quot;, &quot;&#x27;ve&quot;, &#x27;a&#x27;,\n",
       "                             &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                             &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                             &#x27;aren&#x27;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;, &#x27;been&#x27;,\n",
       "                             &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;, &#x27;both&#x27;, ...])</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(max_iter=5000, random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', TextCleaner(strip_whitespace=True)),\n",
       "                ('spacy',\n",
       "                 SpacyPreprocessor(feature_store=<textplumber.store.TextFeatureStore object>)),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('tokens',\n",
       "                                                 Pipeline(steps=[('spacy_token_vectorizer',\n",
       "                                                                  TokensVectorizer(feature_store=<textplumber.store.TextFeatureStore object>,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[\"'d\",\n",
       "                                                                                               \"'ll\",\n",
       "                                                                                               \"'m\",\n",
       "                                                                                               \"'re\",\n",
       "                                                                                               \"'s\",\n",
       "                                                                                               \"'ve\",\n",
       "                                                                                               'a',\n",
       "                                                                                               'about',\n",
       "                                                                                               'above',\n",
       "                                                                                               'after',\n",
       "                                                                                               'again',\n",
       "                                                                                               'against',\n",
       "                                                                                               'ain',\n",
       "                                                                                               'all',\n",
       "                                                                                               'am',\n",
       "                                                                                               'an',\n",
       "                                                                                               'and',\n",
       "                                                                                               'any',\n",
       "                                                                                               'are',\n",
       "                                                                                               'aren',\n",
       "                                                                                               'as',\n",
       "                                                                                               'at',\n",
       "                                                                                               'be',\n",
       "                                                                                               'because',\n",
       "                                                                                               'been',\n",
       "                                                                                               'before',\n",
       "                                                                                               'being',\n",
       "                                                                                               'below',\n",
       "                                                                                               'between',\n",
       "                                                                                               'both', ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# you can uncomment components below to create a more complex pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "\t('cleaner', TextCleaner(strip_whitespace=True)), # for the essay dataset you should use character_replacements = {\"’\": \"'\", '“': '\"', '”': '\"',}\n",
    "\t('spacy', SpacyPreprocessor(feature_store=feature_store)),\n",
    "\t('features', FeatureUnion([\n",
    "\t\t('tokens', # token features - these can be single tokens or ngrams of tokens using TokensVectorizer - see textplumber documentation for examples\n",
    "\t\t\tPipeline([\n",
    "\t\t\t\t('spacy_token_vectorizer', TokensVectorizer(feature_store = feature_store, vectorizer_type='count', max_features=100, lowercase = True, remove_punctuation = True, stop_words = stop_words, min_df=0.0, max_df=1.0, ngram_range=(1, 1))),\n",
    "\t\t\t\t# ('selector', SelectKBest(score_func=mutual_info_classif, k=100)), # uncomment for feature selection\n",
    "\t\t\t\t# ('scaler', StandardScaler(with_mean=False)),\n",
    "\t\t\t\t], verbose = True)),\n",
    "\n",
    "\t\t# ('pos', # pos features - these can be a single label or ngrams of pos tags using POSVectorizer - see textplumber documentation for examples\n",
    "\t\t# \tPipeline([\n",
    "\t\t# \t\t('spacy_pos_vectorizer', POSVectorizer(feature_store=feature_store)),\n",
    "\t\t# \t\t#('selector', SelectKBest(score_func=mutual_info_classif, k=5)),\n",
    "\t\t# \t\t('scaler', StandardScaler(with_mean=False)),\n",
    "\t\t# \t\t], verbose = True)),\n",
    "\n",
    "\t\t# ('textstats', # document-level text statistics using TextstatsTransformer - see textplumber documentation for examples\n",
    "\t\t# \tPipeline([\n",
    "\t\t# \t\t('textstats_vectorizer', TextstatsTransformer(feature_store=feature_store)),\n",
    "\t\t# \t\t('scaler', StandardScaler(with_mean=False)),\n",
    "\t\t# \t\t], verbose = True)),\n",
    "\n",
    "\t\t# ('lexicon', # lexicon features - defined above are empath_lexicons, sentiment_lexicons and stop_words_lexicon - see textplumber documentation for examples\n",
    "\t\t# \tPipeline([\n",
    "\t\t# \t\t('lexicon_vectorizer', LexiconCountVectorizer(feature_store=feature_store, lexicons=empath_lexicons)), # the notebook has already provided example lexicons right at the top!\n",
    "\t\t#  \t\t#('selector', SelectKBest(score_func=mutual_info_classif, k=5)),\n",
    "\t\t# \t\t('scaler', StandardScaler(with_mean=False)),\n",
    "\t\t# \t\t], verbose = True)),\n",
    "\n",
    "\t\t# ('embeddings', Model2VecEmbedder(feature_store=feature_store)), # extract embeddings using Model2Vec - textplumber documentation for examples\n",
    "\n",
    "\t\t], verbose = True)),\n",
    "\t\n",
    "\t('classifier', LogisticRegression(max_iter=5000, random_state=42)) # for logistic regression - only select one classifier!\n",
    "    # ('classifier', DecisionTreeClassifier(max_depth = 3, random_state=42)) # for decision tree - only select one classifier!\n",
    "], verbose = True) # using verbose because I like to see what is going on\n",
    "\n",
    "display(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c2483",
   "metadata": {},
   "source": [
    "Note: the preprocessing stage will be slow the first time you run this cell, but the preprocessed features will be loaded from the feature store on subsequent training using the same training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 4) Processing cleaner, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 4) Processing spacy, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geoff/miniconda3/envs/textplumber/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 1) Processing spacy_token_vectorizer, total=   0.8s\n",
      "[FeatureUnion] ........ (step 1 of 1) Processing tokens, total=   0.8s\n",
      "[Pipeline] .......... (step 3 of 4) Processing features, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 4) Processing classifier, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, TextCleaner(strip_whitespace=True)),\n",
       "                (&#x27;spacy&#x27;,\n",
       "                 SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)),\n",
       "                (&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                                  TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                                               &quot;&#x27;ll&quot;,\n",
       "                                                                                               &quot;&#x27;m&quot;,\n",
       "                                                                                               &quot;&#x27;re&quot;,\n",
       "                                                                                               &quot;&#x27;s&quot;,\n",
       "                                                                                               &quot;&#x27;ve&quot;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;about&#x27;,\n",
       "                                                                                               &#x27;above&#x27;,\n",
       "                                                                                               &#x27;after&#x27;,\n",
       "                                                                                               &#x27;again&#x27;,\n",
       "                                                                                               &#x27;against&#x27;,\n",
       "                                                                                               &#x27;ain&#x27;,\n",
       "                                                                                               &#x27;all&#x27;,\n",
       "                                                                                               &#x27;am&#x27;,\n",
       "                                                                                               &#x27;an&#x27;,\n",
       "                                                                                               &#x27;and&#x27;,\n",
       "                                                                                               &#x27;any&#x27;,\n",
       "                                                                                               &#x27;are&#x27;,\n",
       "                                                                                               &#x27;aren&#x27;,\n",
       "                                                                                               &#x27;as&#x27;,\n",
       "                                                                                               &#x27;at&#x27;,\n",
       "                                                                                               &#x27;be&#x27;,\n",
       "                                                                                               &#x27;because&#x27;,\n",
       "                                                                                               &#x27;been&#x27;,\n",
       "                                                                                               &#x27;before&#x27;,\n",
       "                                                                                               &#x27;being&#x27;,\n",
       "                                                                                               &#x27;below&#x27;,\n",
       "                                                                                               &#x27;between&#x27;,\n",
       "                                                                                               &#x27;both&#x27;, ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, TextCleaner(strip_whitespace=True)),\n",
       "                (&#x27;spacy&#x27;,\n",
       "                 SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)),\n",
       "                (&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                                  TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                                               &quot;&#x27;ll&quot;,\n",
       "                                                                                               &quot;&#x27;m&quot;,\n",
       "                                                                                               &quot;&#x27;re&quot;,\n",
       "                                                                                               &quot;&#x27;s&quot;,\n",
       "                                                                                               &quot;&#x27;ve&quot;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;about&#x27;,\n",
       "                                                                                               &#x27;above&#x27;,\n",
       "                                                                                               &#x27;after&#x27;,\n",
       "                                                                                               &#x27;again&#x27;,\n",
       "                                                                                               &#x27;against&#x27;,\n",
       "                                                                                               &#x27;ain&#x27;,\n",
       "                                                                                               &#x27;all&#x27;,\n",
       "                                                                                               &#x27;am&#x27;,\n",
       "                                                                                               &#x27;an&#x27;,\n",
       "                                                                                               &#x27;and&#x27;,\n",
       "                                                                                               &#x27;any&#x27;,\n",
       "                                                                                               &#x27;are&#x27;,\n",
       "                                                                                               &#x27;aren&#x27;,\n",
       "                                                                                               &#x27;as&#x27;,\n",
       "                                                                                               &#x27;at&#x27;,\n",
       "                                                                                               &#x27;be&#x27;,\n",
       "                                                                                               &#x27;because&#x27;,\n",
       "                                                                                               &#x27;been&#x27;,\n",
       "                                                                                               &#x27;before&#x27;,\n",
       "                                                                                               &#x27;being&#x27;,\n",
       "                                                                                               &#x27;below&#x27;,\n",
       "                                                                                               &#x27;between&#x27;,\n",
       "                                                                                               &#x27;both&#x27;, ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TextCleaner</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TextCleaner(strip_whitespace=True)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SpacyPreprocessor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SpacyPreprocessor(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>features: FeatureUnion</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.FeatureUnion.html\">?<span>Documentation for features: FeatureUnion</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FeatureUnion(transformer_list=[(&#x27;tokens&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;spacy_token_vectorizer&#x27;,\n",
       "                                                 TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,\n",
       "                                                                  lowercase=True,\n",
       "                                                                  max_features=100,\n",
       "                                                                  min_df=0.0,\n",
       "                                                                  remove_punctuation=True,\n",
       "                                                                  stop_words=[&quot;&#x27;d&quot;,\n",
       "                                                                              &quot;&#x27;ll&quot;,\n",
       "                                                                              &quot;&#x27;m&quot;,\n",
       "                                                                              &quot;&#x27;re&quot;,\n",
       "                                                                              &quot;&#x27;s&quot;,\n",
       "                                                                              &quot;&#x27;ve&quot;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;about&#x27;,\n",
       "                                                                              &#x27;above&#x27;,\n",
       "                                                                              &#x27;after&#x27;,\n",
       "                                                                              &#x27;again&#x27;,\n",
       "                                                                              &#x27;against&#x27;,\n",
       "                                                                              &#x27;ain&#x27;,\n",
       "                                                                              &#x27;all&#x27;,\n",
       "                                                                              &#x27;am&#x27;,\n",
       "                                                                              &#x27;an&#x27;,\n",
       "                                                                              &#x27;and&#x27;,\n",
       "                                                                              &#x27;any&#x27;,\n",
       "                                                                              &#x27;are&#x27;,\n",
       "                                                                              &#x27;aren&#x27;,\n",
       "                                                                              &#x27;as&#x27;,\n",
       "                                                                              &#x27;at&#x27;,\n",
       "                                                                              &#x27;be&#x27;,\n",
       "                                                                              &#x27;because&#x27;,\n",
       "                                                                              &#x27;been&#x27;,\n",
       "                                                                              &#x27;before&#x27;,\n",
       "                                                                              &#x27;being&#x27;,\n",
       "                                                                              &#x27;below&#x27;,\n",
       "                                                                              &#x27;between&#x27;,\n",
       "                                                                              &#x27;both&#x27;, ...]))],\n",
       "                                         verbose=True))],\n",
       "             verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>tokens</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TokensVectorizer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TokensVectorizer(feature_store=&lt;textplumber.store.TextFeatureStore object at 0x7f3dbe976890&gt;,\n",
       "                 lowercase=True, max_features=100, min_df=0.0,\n",
       "                 remove_punctuation=True,\n",
       "                 stop_words=[&quot;&#x27;d&quot;, &quot;&#x27;ll&quot;, &quot;&#x27;m&quot;, &quot;&#x27;re&quot;, &quot;&#x27;s&quot;, &quot;&#x27;ve&quot;, &#x27;a&#x27;,\n",
       "                             &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                             &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                             &#x27;aren&#x27;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;, &#x27;been&#x27;,\n",
       "                             &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;, &#x27;both&#x27;, ...])</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=5000, random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', TextCleaner(strip_whitespace=True)),\n",
       "                ('spacy',\n",
       "                 SpacyPreprocessor(feature_store=<textplumber.store.TextFeatureStore object>)),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('tokens',\n",
       "                                                 Pipeline(steps=[('spacy_token_vectorizer',\n",
       "                                                                  TokensVectorizer(feature_store=<textplumber.store.TextFeatureStore object>,...\n",
       "                                                                                   remove_punctuation=True,\n",
       "                                                                                   stop_words=[\"'d\",\n",
       "                                                                                               \"'ll\",\n",
       "                                                                                               \"'m\",\n",
       "                                                                                               \"'re\",\n",
       "                                                                                               \"'s\",\n",
       "                                                                                               \"'ve\",\n",
       "                                                                                               'a',\n",
       "                                                                                               'about',\n",
       "                                                                                               'above',\n",
       "                                                                                               'after',\n",
       "                                                                                               'again',\n",
       "                                                                                               'against',\n",
       "                                                                                               'ain',\n",
       "                                                                                               'all',\n",
       "                                                                                               'am',\n",
       "                                                                                               'an',\n",
       "                                                                                               'and',\n",
       "                                                                                               'any',\n",
       "                                                                                               'are',\n",
       "                                                                                               'aren',\n",
       "                                                                                               'as',\n",
       "                                                                                               'at',\n",
       "                                                                                               'be',\n",
       "                                                                                               'because',\n",
       "                                                                                               'been',\n",
       "                                                                                               'before',\n",
       "                                                                                               'being',\n",
       "                                                                                               'below',\n",
       "                                                                                               'between',\n",
       "                                                                                               'both', ...]))],\n",
       "                                                          verbose=True))],\n",
       "                              verbose=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=5000, random_state=42))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f970c0",
   "metadata": {},
   "source": [
    "Run the predictions and output model metrics and a confusion matrix using this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "y_predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4018fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg      0.708     0.690     0.699       200\n",
      "         pos      0.698     0.715     0.706       200\n",
      "\n",
      "    accuracy                          0.703       400\n",
      "   macro avg      0.703     0.702     0.702       400\n",
      "weighted avg      0.703     0.703     0.702       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="567.31975pt" height="520.06375pt" viewBox="0 0 567.31975 520.06375" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2025-08-07T12:02:23.093696</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.10.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 520.06375 
L 567.31975 520.06375 
L 567.31975 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 37.55625 450.72 
L 483.95625 450.72 
L 483.95625 7.2 
L 37.55625 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="QuadMesh_1">
    <path d="M 37.55625 7.2 
L 260.75625 7.2 
L 260.75625 228.96 
L 37.55625 228.96 
L 37.55625 7.2 
" clip-path="url(#peea4af5d6a)" style="fill: #083e81"/>
    <path d="M 260.75625 7.2 
L 483.95625 7.2 
L 483.95625 228.96 
L 260.75625 228.96 
L 260.75625 7.2 
" clip-path="url(#peea4af5d6a)" style="fill: #ecf4fb"/>
    <path d="M 37.55625 228.96 
L 260.75625 228.96 
L 260.75625 450.72 
L 37.55625 450.72 
L 37.55625 228.96 
" clip-path="url(#peea4af5d6a)" style="fill: #f7fbff"/>
    <path d="M 260.75625 228.96 
L 483.95625 228.96 
L 483.95625 450.72 
L 260.75625 450.72 
L 260.75625 228.96 
" clip-path="url(#peea4af5d6a)" style="fill: #08306b"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="mc6277a7f19" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mc6277a7f19" x="149.15625" y="450.72" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(139.736719 465.318437)">neg</text>
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(120.760938 476.51625)">(Total: 195)</text>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#mc6277a7f19" x="372.35625" y="450.72" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(363.517969 465.318437)">pos</text>
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(343.960938 476.51625)">(Total: 205)</text>
     </g>
    </g>
    <g id="text_3">
     <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="260.75625" y="490.194375" transform="rotate(-0 260.75625 490.194375)">Predicted Labels</text>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_3">
      <defs>
       <path id="m71ca42fdd1" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m71ca42fdd1" x="37.55625" y="118.08" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(28.476563 157.483906) rotate(-90)">neg (Total: 200)</text>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_4">
      <g>
       <use xlink:href="#m71ca42fdd1" x="37.55625" y="339.84" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(28.476563 378.662656) rotate(-90)">pos (Total: 200)</text>
     </g>
    </g>
    <g id="text_6">
     <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="14.798438" y="228.96" transform="rotate(-90 14.798438 228.96)">Actual Labels</text>
    </g>
   </g>
   <g id="text_7">
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #ffffff" transform="translate(139.6125 115.240469)">138</text>
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #ffffff" transform="translate(134.121875 126.438281)">(0.69)</text>
   </g>
   <g id="text_8">
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #262626" transform="translate(365.99375 115.240469)">62</text>
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #262626" transform="translate(357.321875 126.438281)">(0.31)</text>
   </g>
   <g id="text_9">
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #262626" transform="translate(142.79375 337.000469)">57</text>
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #262626" transform="translate(134.121875 348.198281)">(0.28)</text>
   </g>
   <g id="text_10">
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #ffffff" transform="translate(362.8125 337.000469)">143</text>
    <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; fill: #ffffff" transform="translate(357.321875 348.198281)">(0.71)</text>
   </g>
  </g>
  <g id="axes_2">
   <g id="patch_3">
    <path d="M 511.85625 450.72 
L 534.03225 450.72 
L 534.03225 7.2 
L 511.85625 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <image xlink:href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAAB8AAAJoCAYAAACeFjppAAAC9ElEQVR4nO3dQU4DUQwE0QTl/tdlEYnhFn6L6rqAZf92zScZ4P37fZ4X4kcV5sU/bui885drPRw4OHUeOMck0yveNVxXMjpwjhmO0JXMArfineLdwHUN1z1zHTjH7u294jMcQZ+5I7xqWcN1JTPDEbqG6545dnvVcAscYYYj6DOPSmb3dkJXMjMcYYYjzHCESaZXvGu4rmR04BwzHKErmRmO0JXMDEfoGq4rGR04xyTTKz7DEfSZO8qrFg5cVDIzHKFruK5kdOCihutKRgfOMcMRupKZ4Qhdydix/0HFLXC94nukErRkXPHyqmUDl5XMAkfoGq575jMcods5Nlx1z7uBm9sJ4cBlJbPAEbofAn6e6ge/2nCOBa5XfIYjTDK94uHAZS+Qczthry0QyquWDdwuE4LuI7Xr9gWO0A1c97WFrRphX/AQyoELd75Vu2erRkgHLrrn3cB1O9efvW7V7ikHrjr27u11q0bYqhEWOIL+ENCxVesVL69atXMduOiedwPX7XyrRuheoxY4QvcapR8sC9w9uvPomeuxu+KTTK9497c5uobbD4qEcOCyTzU99mrgsobrnvmuUYTd2wndR2rXcN0zn+EICxwhbLjwvb36Zr9eNVdcd77A3VM2XDVwXcnoVVvg7gkHboYTLHAE3bkrrjuPnvnGTuiumh77AneP7jx65nrsrrjufIG7Z4Ej6M5d8fSqLXD3LHAE3bkrrjuPnvnGTuiumh77AncP/hYZvrGRXjVXXHe+wN2zwBF05654etW6gYt2bscO361f4ILFu2Nf54Twqs3tgnDgsmMPd56VzAJH6Ha+sRPCnc/tgnDgsp1v7ISu4bpnvrETup1v7IS5nbBVI6zzXvHu2Od2wlaNoFct2rkeu/sfkrrzBe6eBY6gO4+e+cZO6K6aHvsCd4/uPHrmeuwL3D0LHEF3Hg1c98z12LOB2596AJQDF+58q3bPAkdY4Ai682jgumeux77A3bPAEXTn0cB1z1yPPRq4f5kgHYzoLwuTAAAAAElFTkSuQmCC" id="image815d3969e1" transform="scale(1 -1) translate(0 -443.52)" x="511.92" y="-7.2" width="22.32" height="443.52"/>
   <g id="matplotlib.axis_3"/>
   <g id="matplotlib.axis_4">
    <g id="ytick_3">
     <g id="line2d_5">
      <defs>
       <path id="m689656336a" d="M 0 0 
L 3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="435.248372" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="439.047591" transform="rotate(-0 541.03225 439.047591)">60</text>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_6">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="383.676279" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="387.475498" transform="rotate(-0 541.03225 387.475498)">70</text>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_7">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="332.104186" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="335.903405" transform="rotate(-0 541.03225 335.903405)">80</text>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_8">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="280.532093" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_14">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="284.331312" transform="rotate(-0 541.03225 284.331312)">90</text>
     </g>
    </g>
    <g id="ytick_7">
     <g id="line2d_9">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_15">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="232.759219" transform="rotate(-0 541.03225 232.759219)">100</text>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_10">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="177.387907" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_16">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="181.187126" transform="rotate(-0 541.03225 181.187126)">110</text>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_11">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="125.815814" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_17">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="129.615033" transform="rotate(-0 541.03225 129.615033)">120</text>
     </g>
    </g>
    <g id="ytick_10">
     <g id="line2d_12">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="74.243721" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_18">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="78.04294" transform="rotate(-0 541.03225 78.04294)">130</text>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_13">
      <g>
       <use xlink:href="#m689656336a" x="534.03225" y="22.671628" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_19">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: start" x="541.03225" y="26.470847" transform="rotate(-0 541.03225 26.470847)">140</text>
     </g>
    </g>
   </g>
   <g id="LineCollection_1"/>
   <g id="patch_4">
    <path d="M 511.85625 450.72 
L 522.94425 450.72 
L 534.03225 450.72 
L 534.03225 7.2 
L 522.94425 7.2 
L 511.85625 7.2 
L 511.85625 450.72 
z
" style="fill: none"/>
   </g>
  </g>
  <g id="text_20">
   <text style="font-size: 8px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(19.55625 502.24175)">Note: cells show counts and row-wise proportions.</text>
   <text style="font-size: 8px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif" transform="translate(19.55625 511.2)"/>
  </g>
 </g>
 <defs>
  <clipPath id="peea4af5d6a">
   <rect x="37.55625" y="7.2" width="446.4" height="443.52"/>
  </clipPath>
 </defs>
</svg>
\"></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(classification_report(y_test, y_predicted, target_names = target_names, digits=3))\n",
    "plot_confusion_matrix(y_test, y_predicted, target_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accca8ed",
   "metadata": {},
   "source": [
    "The cell below is commented out, but you have the option to uncomment it to run a grid search based on the pipeline you've created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c76909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# # Note: if you get a warning about tokenizers and parallelism - uncomment this line \n",
    "# # os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# \n",
    "# # setup gridsearch to test different max_features\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {\n",
    "#     'features__tokens__spacy_token_vectorizer__max_features': [50, 100, 150, 200, 250, 300],  # this assumes you are using the tokens part of the pipeline\n",
    "#     # 'features__tokens__selector__k': [50, 100, 150, 200, 250, 300],  # this assumes you have enabled the selector for tokens\n",
    "# }\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', verbose=100, n_jobs=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print('\\n-----------------------------------------------------------------')\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best score found: \", grid_search.best_score_)\n",
    "# print('-----------------------------------------------------------------\\n')\n",
    "\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# print(classification_report(y_test, y_pred, target_names = target_names, digits=3))\n",
    "# plot_confusion_matrix(y_test, y_pred, target_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab181500",
   "metadata": {},
   "source": [
    "## 4. Evaluate your model and investigate model predictions\n",
    "\n",
    "You already have some metrics in the cell above. Below is some additional reporting to help you understand your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2103831",
   "metadata": {},
   "source": [
    "### 4.1 Understand feature extraction and selection\n",
    "\n",
    "Use `preview_pipeline_features` to examine the features being extracted and selected by the steps of your pipeline. The final classifier step will show the features input for training the classifier.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba08646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t<style>\n",
       "\tdetails {\n",
       "\t\tbackground:#f0f0f0;\n",
       "\t\tcolor:#000;\n",
       "\t\tborder-radius: 0.5em; \n",
       "\t\tpadding: 0;\n",
       "\t\tmargin-bottom:1em;\n",
       "\t\tborder: 1px solid #ccc;\n",
       "\t\twidth: auto;\n",
       "        font-size: 0.9em;\n",
       "        overflow-wrap: break-word;\n",
       "\t}\n",
       "\t\t\t\n",
       "\tdetails summary {\n",
       "\t\tcursor: pointer;\n",
       "\t\tfont-weight: bold;\n",
       "\t\tfont-size: 1em;\n",
       "\t\tpadding: 1em;\n",
       "\t\tcolor: #666;\n",
       "\t}\n",
       "\n",
       "\tdetails.warnings {\n",
       "\t\tbackground-color: #f8d7da;\n",
       "\t}\n",
       "\t\t\t\n",
       "\tdetails.notices {\n",
       "\t\tbackground-color: #d4edda;\n",
       "\t}\n",
       "\n",
       "\tdetails[open] summary {\n",
       "\t\tcolor: black;\n",
       "\t\tmargin-bottom: 1em;\n",
       "\t}\n",
       "\tdetails ul, details p {\n",
       "\t\tmargin-left: 1em;\n",
       "\t}\n",
       "\tdetails pre {\n",
       "\t\tbackground-color: #f0f0f0;\n",
       "\t\toverflow: auto;\n",
       "\t}\n",
       "\tdetails h4, .featureunion > h4 {\n",
       "\t\tmargin: 0;\n",
       "\t\tmargin-left: 1em;\n",
       "\t\tpadding: 0;\n",
       "\t\tfont-size: 1em;\n",
       "\t}\n",
       "\n",
       "\t.featureunion > h4 {\n",
       "\tmargin: 1em;\n",
       "\t}\n",
       "\n",
       "\tdetails {\n",
       "\twidth: 100%;\n",
       "\t}\n",
       "\n",
       "\t.featureunion {\n",
       "\twidth:100%;\n",
       "\tborder: 1px dashed #ccc;\n",
       "\tborder-radius: 0.5em; \n",
       "\tmargin-bottom:1em;\n",
       "\t}\n",
       "\n",
       "\t.featureunion-column {\n",
       "\tfloat: left;\n",
       "\tmargin: 0.5%;\n",
       "\t}\n",
       "\n",
       "\t.featureunion::after {\n",
       "\tcontent: '';\n",
       "\tdisplay: table;\n",
       "\tclear: both;\n",
       "\t}\t\t\n",
       "\t</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t<details>\n",
       "\t<summary>cleaner TextCleaner</summary>\n",
       "\t<p>This step receives and returns text.</p>\n",
       "\t</details>\n",
       "\t\n",
       "\t<details>\n",
       "\t<summary>spacy SpacyPreprocessor</summary>\n",
       "\t<p>This step receives and returns text.</p>\n",
       "\t</details>\n",
       "\t<div class=\"featureunion\"><h4>features FeatureUnion</h4><div class=\"featureunion-column\" style=\"width: 98.9%\">\n",
       "\t<details>\n",
       "\t<summary>spacy_token_vectorizer TokensVectorizer</summary>\n",
       "\t<h4>Features Out (100)</h4><p>action, actually, almost, also, although, another, around, audience, back, bad, best, better, big,\n",
       "cast, character, characters, come, comedy, comes, director, end, enough, even, ever, every, fact,\n",
       "film, films, find, first, funny, get, gets, go, going, good, great, however, john, know, last, life,\n",
       "like, little, long, look, love, made, make, makes, man, many, may, movie, movies, much, never, new,\n",
       "nothing, old, one, people, performance, played, plays, plot, real, really, right, role, say, scene,\n",
       "scenes, script, see, seems, seen, show, since, something, star, still, story, take, thing, things,\n",
       "think, though, three, time, two, us, way, well, without, work, world, year, years, young</p>\n",
       "\t</details>\n",
       "\t</div></div>\n",
       "\t<details>\n",
       "\t<summary>classifier LogisticRegression</summary>\n",
       "\t<h4>Features In (100)</h4><p>tokens__action, tokens__actually, tokens__almost, tokens__also, tokens__although, tokens__another,\n",
       "tokens__around, tokens__audience, tokens__back, tokens__bad, tokens__best, tokens__better,\n",
       "tokens__big, tokens__cast, tokens__character, tokens__characters, tokens__come, tokens__comedy,\n",
       "tokens__comes, tokens__director, tokens__end, tokens__enough, tokens__even, tokens__ever,\n",
       "tokens__every, tokens__fact, tokens__film, tokens__films, tokens__find, tokens__first,\n",
       "tokens__funny, tokens__get, tokens__gets, tokens__go, tokens__going, tokens__good, tokens__great,\n",
       "tokens__however, tokens__john, tokens__know, tokens__last, tokens__life, tokens__like,\n",
       "tokens__little, tokens__long, tokens__look, tokens__love, tokens__made, tokens__make, tokens__makes,\n",
       "tokens__man, tokens__many, tokens__may, tokens__movie, tokens__movies, tokens__much, tokens__never,\n",
       "tokens__new, tokens__nothing, tokens__old, tokens__one, tokens__people, tokens__performance,\n",
       "tokens__played, tokens__plays, tokens__plot, tokens__real, tokens__really, tokens__right,\n",
       "tokens__role, tokens__say, tokens__scene, tokens__scenes, tokens__script, tokens__see,\n",
       "tokens__seems, tokens__seen, tokens__show, tokens__since, tokens__something, tokens__star,\n",
       "tokens__still, tokens__story, tokens__take, tokens__thing, tokens__things, tokens__think,\n",
       "tokens__though, tokens__three, tokens__time, tokens__two, tokens__us, tokens__way, tokens__well,\n",
       "tokens__without, tokens__work, tokens__world, tokens__year, tokens__years, tokens__young</p>\n",
       "\t</details>\n",
       "\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "preview_pipeline_features(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bddd74",
   "metadata": {},
   "source": [
    "### 4.2 Classifier-specific features\n",
    "\n",
    "If you are using a Decision Tree classifier in your pipeline, this will plot it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d02568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier is not a decision tree - so no plot is shown!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "if pipeline.named_steps['classifier'].__class__.__name__ == 'DecisionTreeClassifier':\n",
    "    plot_decision_tree_from_pipeline(pipeline, X_train, y_train, target_classes, target_names, 'classifier', 'features')\n",
    "else:\n",
    "    print('The classifier is not a decision tree - so no plot is shown!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16044bcb",
   "metadata": {},
   "source": [
    "If you are using a Logistic Regression classifier in your pipeline, this will plot the coefficients of the features in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="712.240625pt" height="427.869844pt" viewBox="0 0 712.240625 427.869844" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2025-08-07T12:02:23.224921</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.10.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 427.869844 
L 712.240625 427.869844 
L 712.240625 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 135.090625 375.598125 
L 705.040625 375.598125 
L 705.040625 22.318125 
L 135.090625 22.318125 
z
" style="fill: #ffffff"/>
   </g>
   <g id="patch_3">
    <path d="M 477.928976 24.084525 
L 160.997443 24.084525 
L 160.997443 38.215725 
L 477.928976 38.215725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_4">
    <path d="M 477.928976 41.748525 
L 244.32733 41.748525 
L 244.32733 55.879725 
L 477.928976 55.879725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_5">
    <path d="M 477.928976 59.412525 
L 261.914955 59.412525 
L 261.914955 73.543725 
L 477.928976 73.543725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_6">
    <path d="M 477.928976 77.076525 
L 679.133807 77.076525 
L 679.133807 91.207725 
L 477.928976 91.207725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_7">
    <path d="M 477.928976 94.740525 
L 289.533179 94.740525 
L 289.533179 108.871725 
L 477.928976 108.871725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_8">
    <path d="M 477.928976 112.404525 
L 305.143785 112.404525 
L 305.143785 126.535725 
L 477.928976 126.535725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_9">
    <path d="M 477.928976 130.068525 
L 633.516321 130.068525 
L 633.516321 144.199725 
L 477.928976 144.199725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_10">
    <path d="M 477.928976 147.732525 
L 616.766236 147.732525 
L 616.766236 161.863725 
L 477.928976 161.863725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_11">
    <path d="M 477.928976 165.396525 
L 612.978936 165.396525 
L 612.978936 179.527725 
L 477.928976 179.527725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_12">
    <path d="M 477.928976 183.060525 
L 612.561635 183.060525 
L 612.561635 197.191725 
L 477.928976 197.191725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_13">
    <path d="M 477.928976 200.724525 
L 609.451643 200.724525 
L 609.451643 214.855725 
L 477.928976 214.855725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_14">
    <path d="M 477.928976 218.388525 
L 353.925471 218.388525 
L 353.925471 232.519725 
L 477.928976 232.519725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_15">
    <path d="M 477.928976 236.052525 
L 600.999154 236.052525 
L 600.999154 250.183725 
L 477.928976 250.183725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_16">
    <path d="M 477.928976 253.716525 
L 592.418266 253.716525 
L 592.418266 267.847725 
L 477.928976 267.847725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_17">
    <path d="M 477.928976 271.380525 
L 366.081613 271.380525 
L 366.081613 285.511725 
L 477.928976 285.511725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_18">
    <path d="M 477.928976 289.044525 
L 586.287735 289.044525 
L 586.287735 303.175725 
L 477.928976 303.175725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_19">
    <path d="M 477.928976 306.708525 
L 375.411515 306.708525 
L 375.411515 320.839725 
L 477.928976 320.839725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_20">
    <path d="M 477.928976 324.372525 
L 578.679221 324.372525 
L 578.679221 338.503725 
L 477.928976 338.503725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_21">
    <path d="M 477.928976 342.036525 
L 576.71389 342.036525 
L 576.71389 356.167725 
L 477.928976 356.167725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="patch_22">
    <path d="M 477.928976 359.700525 
L 568.708737 359.700525 
L 568.708737 373.831725 
L 477.928976 373.831725 
z
" clip-path="url(#p9bdb33bae1)" style="fill: #3274a1"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="mfc2e406b28" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mfc2e406b28" x="191.112938" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="191.112938" y="390.196563" transform="rotate(-0 191.112938 390.196563)">−0.6</text>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#mfc2e406b28" x="286.718284" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="286.718284" y="390.196563" transform="rotate(-0 286.718284 390.196563)">−0.4</text>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <g>
       <use xlink:href="#mfc2e406b28" x="382.32363" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="382.32363" y="390.196563" transform="rotate(-0 382.32363 390.196563)">−0.2</text>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <g>
       <use xlink:href="#mfc2e406b28" x="477.928976" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="477.928976" y="390.196563" transform="rotate(-0 477.928976 390.196563)">0.0</text>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <g>
       <use xlink:href="#mfc2e406b28" x="573.534322" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="573.534322" y="390.196563" transform="rotate(-0 573.534322 390.196563)">0.2</text>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_6">
      <g>
       <use xlink:href="#mfc2e406b28" x="669.139668" y="375.598125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="669.139668" y="390.196563" transform="rotate(-0 669.139668 390.196563)">0.4</text>
     </g>
    </g>
    <g id="text_7">
     <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="420.065625" y="403.874688" transform="rotate(-0 420.065625 403.874688)">Log Odds (Logit)</text>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_7">
      <defs>
       <path id="m07a652a08c" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="31.150125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="34.949344" transform="rotate(-0 128.090625 34.949344)">tokens__bad</text>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_8">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="48.814125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="52.613344" transform="rotate(-0 128.090625 52.613344)">tokens__script</text>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_9">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="66.478125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="70.277344" transform="rotate(-0 128.090625 70.277344)">tokens__better</text>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_10">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="84.142125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="87.941344" transform="rotate(-0 128.090625 87.941344)">tokens__great</text>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_11">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="101.806125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="105.605344" transform="rotate(-0 128.090625 105.605344)">tokens__nothing</text>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_12">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="119.470125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="123.269344" transform="rotate(-0 128.090625 123.269344)">tokens__plot</text>
     </g>
    </g>
    <g id="ytick_7">
     <g id="line2d_13">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="137.134125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_14">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="140.933344" transform="rotate(-0 128.090625 140.933344)">tokens__although</text>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_14">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="154.798125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_15">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="158.597344" transform="rotate(-0 128.090625 158.597344)">tokens__well</text>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_15">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="172.462125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_16">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="176.261344" transform="rotate(-0 128.090625 176.261344)">tokens__performance</text>
     </g>
    </g>
    <g id="ytick_10">
     <g id="line2d_16">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="190.126125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_17">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="193.925344" transform="rotate(-0 128.090625 193.925344)">tokens__seen</text>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_17">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="207.790125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_18">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="211.589344" transform="rotate(-0 128.090625 211.589344)">tokens__best</text>
     </g>
    </g>
    <g id="ytick_12">
     <g id="line2d_18">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="225.454125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_19">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="229.253344" transform="rotate(-0 128.090625 229.253344)">tokens__actually</text>
     </g>
    </g>
    <g id="ytick_13">
     <g id="line2d_19">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="243.118125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_20">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="246.917344" transform="rotate(-0 128.090625 246.917344)">tokens__world</text>
     </g>
    </g>
    <g id="ytick_14">
     <g id="line2d_20">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="260.782125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_21">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="264.581344" transform="rotate(-0 128.090625 264.581344)">tokens__many</text>
     </g>
    </g>
    <g id="ytick_15">
     <g id="line2d_21">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="278.446125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_22">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="282.245344" transform="rotate(-0 128.090625 282.245344)">tokens__made</text>
     </g>
    </g>
    <g id="ytick_16">
     <g id="line2d_22">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="296.110125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_23">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="299.909344" transform="rotate(-0 128.090625 299.909344)">tokens__right</text>
     </g>
    </g>
    <g id="ytick_17">
     <g id="line2d_23">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="313.774125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_24">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="317.573344" transform="rotate(-0 128.090625 317.573344)">tokens__director</text>
     </g>
    </g>
    <g id="ytick_18">
     <g id="line2d_24">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="331.438125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_25">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="335.237344" transform="rotate(-0 128.090625 335.237344)">tokens__without</text>
     </g>
    </g>
    <g id="ytick_19">
     <g id="line2d_25">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="349.102125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_26">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="352.901344" transform="rotate(-0 128.090625 352.901344)">tokens__also</text>
     </g>
    </g>
    <g id="ytick_20">
     <g id="line2d_26">
      <g>
       <use xlink:href="#m07a652a08c" x="135.090625" y="366.766125" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_27">
      <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: end" x="128.090625" y="370.565344" transform="rotate(-0 128.090625 370.565344)">tokens__ever</text>
     </g>
    </g>
    <g id="text_28">
     <text style="font-size: 10px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="14.798438" y="198.958125" transform="rotate(-90 14.798438 198.958125)">Feature</text>
    </g>
   </g>
   <g id="line2d_27">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_28">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_29">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_30">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_31">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_32">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_33">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_34">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_35">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_36">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_37">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_38">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_39">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_40">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_41">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_42">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_43">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_44">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_45">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="line2d_46">
    <path clip-path="url(#p9bdb33bae1)" style="fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: square"/>
   </g>
   <g id="patch_23">
    <path d="M 135.090625 375.598125 
L 135.090625 22.318125 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_24">
    <path d="M 705.040625 375.598125 
L 705.040625 22.318125 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_25">
    <path d="M 135.090625 375.598125 
L 705.040625 375.598125 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_26">
    <path d="M 135.090625 22.318125 
L 705.040625 22.318125 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_29">
    <text style="font-size: 12px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="420.065625" y="16.318125" transform="rotate(-0 420.065625 16.318125)">Most Discriminative Features (Log Odds)</text>
   </g>
  </g>
  <g id="text_30">
   <text style="font-size: 9px; font-family: 'Tahoma', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', sans-serif; text-anchor: middle" x="355.840625" y="418.798125" transform="rotate(-0 355.840625 418.798125)">Top 20 features ranked on Absolute Log Odds (Logit). Direction indicates positive/negative association with class 'pos'.</text>
  </g>
 </g>
 <defs>
  <clipPath id="p9bdb33bae1">
   <rect x="135.090625" y="22.318125" width="569.95" height="353.28"/>
  </clipPath>
 </defs>
</svg>
\"></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Log Odds (Logit)</th>\n",
       "      <th>Odds Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tokens__bad</td>\n",
       "      <td>-0.663000</td>\n",
       "      <td>0.515303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tokens__script</td>\n",
       "      <td>-0.488679</td>\n",
       "      <td>0.613436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tokens__better</td>\n",
       "      <td>-0.451887</td>\n",
       "      <td>0.636426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tokens__great</td>\n",
       "      <td>0.420907</td>\n",
       "      <td>1.523343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tokens__nothing</td>\n",
       "      <td>-0.394111</td>\n",
       "      <td>0.674279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tokens__plot</td>\n",
       "      <td>-0.361455</td>\n",
       "      <td>0.696662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokens__although</td>\n",
       "      <td>0.325478</td>\n",
       "      <td>1.384693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tokens__well</td>\n",
       "      <td>0.290438</td>\n",
       "      <td>1.337013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tokens__performance</td>\n",
       "      <td>0.282515</td>\n",
       "      <td>1.326462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tokens__seen</td>\n",
       "      <td>0.281643</td>\n",
       "      <td>1.325305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tokens__best</td>\n",
       "      <td>0.275137</td>\n",
       "      <td>1.316711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokens__actually</td>\n",
       "      <td>-0.259407</td>\n",
       "      <td>0.771509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tokens__world</td>\n",
       "      <td>0.257455</td>\n",
       "      <td>1.293633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tokens__many</td>\n",
       "      <td>0.239504</td>\n",
       "      <td>1.270619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tokens__made</td>\n",
       "      <td>-0.233977</td>\n",
       "      <td>0.791380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tokens__right</td>\n",
       "      <td>0.226679</td>\n",
       "      <td>1.254427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tokens__director</td>\n",
       "      <td>-0.214460</td>\n",
       "      <td>0.806977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tokens__without</td>\n",
       "      <td>0.210763</td>\n",
       "      <td>1.234619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tokens__also</td>\n",
       "      <td>0.206651</td>\n",
       "      <td>1.229554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tokens__ever</td>\n",
       "      <td>0.189905</td>\n",
       "      <td>1.209135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Log Odds (Logit)  Odds Ratio\n",
       "9           tokens__bad         -0.663000    0.515303\n",
       "73       tokens__script         -0.488679    0.613436\n",
       "11       tokens__better         -0.451887    0.636426\n",
       "36        tokens__great          0.420907    1.523343\n",
       "58      tokens__nothing         -0.394111    0.674279\n",
       "65         tokens__plot         -0.361455    0.696662\n",
       "4      tokens__although          0.325478    1.384693\n",
       "93         tokens__well          0.290438    1.337013\n",
       "62  tokens__performance          0.282515    1.326462\n",
       "76         tokens__seen          0.281643    1.325305\n",
       "10         tokens__best          0.275137    1.316711\n",
       "1      tokens__actually         -0.259407    0.771509\n",
       "96        tokens__world          0.257455    1.293633\n",
       "51         tokens__many          0.239504    1.270619\n",
       "47         tokens__made         -0.233977    0.791380\n",
       "68        tokens__right          0.226679    1.254427\n",
       "19     tokens__director         -0.214460    0.806977\n",
       "94      tokens__without          0.210763    1.234619\n",
       "3          tokens__also          0.206651    1.229554\n",
       "23         tokens__ever          0.189905    1.209135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "if pipeline.named_steps['classifier'].__class__.__name__ == 'LogisticRegression':\n",
    "\tplot_logistic_regression_features_from_pipeline(pipeline, target_classes, target_names, top_n=20, classifier_step_name = 'classifier', features_step_name = 'features')\n",
    "else:\n",
    "\tprint('The classifier is not a logistic regression - so no plot is shown!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2e17b",
   "metadata": {},
   "source": [
    "### 4.3 Investigate correct and incorrect predictions\n",
    "\n",
    "To see the predictions of your model run this cell. The output can be quite long depending on the dataset and the number of misclassifications. The Pandas `max_rows` is configured at the top of the cell to restrict the length of output. You can adjust this as required. This is reset back to the Pandas default at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b30f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CORRECTLY CLASSIFIED: neg\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>text</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>dr dolittle ( 20th century fox ) running time : 1 hour 25 minutes starring eddie murphy directed by betty thomas riding high on the success of the nutty professor ( 1996 ) , murphy returns in this abysmal comedy . \\nhe plays doctor john dolittle , who as a child had the ability to understand animals . \\nhowever , after being 'exorcised' he loses this ability , and we fast forward to see dolittle in a crummy job surrounding by crummy people ( most notably dr mark weller , played by oliver pla...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>\" spawn \" features good guys , bad guys , lots of fighting , bloody violence , a leather-clad machine gun chick , gooey , self-healing bullet holes , scatological humor and a man-eating monster . \\nit not only appears to have been tailor made for a swarm of 12- and 13-year-old boys , it appears to have been made by them . \\nin a classic example of telling and not showing , \" spawn \" opens with a truckload of mumbo jumbo about forces of darkness , forces of light and how \" men are the ones w...</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>it's difficult to expect much from a director whose greatest accomplishments to date are a handful of \" award-winning \" tv commercials , as is the case with bubble boy director blair hayes . \\nthat said , hayes's feature film debut lives up to expectations , coming off mainly as equal parts offensive and moronic . \\nbut occasionally , bubble boy transcends its substandard roots with glimmers of humor and scathing social commentary . \\nthose moments of intelligence are delivered mostly by the...</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>whether you like the beatles or not , nobody wants to see the bee gee's take on some of the fab four's best known songs . \\nwell , maybe that's not true . \\n . \\n . \\nmaybe you're curious , the way you have to look in your hanky after you blow your nose . \\nyou just have to know how bad bad can be . \\nif that's the case , rejoice , because it was twenty years ago today ( or so ) that sgt . \\npepper's lonely hearts club band was released ( unleashed ? ) to the world , and thanks to our modern...</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true predicted  correct  \\\n",
       "0    neg       neg     True   \n",
       "1    neg       neg     True   \n",
       "..   ...       ...      ...   \n",
       "396  neg       neg     True   \n",
       "397  neg       neg     True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "0    dr dolittle ( 20th century fox ) running time : 1 hour 25 minutes starring eddie murphy directed by betty thomas riding high on the success of the nutty professor ( 1996 ) , murphy returns in this abysmal comedy . \\nhe plays doctor john dolittle , who as a child had the ability to understand animals . \\nhowever , after being 'exorcised' he loses this ability , and we fast forward to see dolittle in a crummy job surrounding by crummy people ( most notably dr mark weller , played by oliver pla...   \n",
       "1     \" spawn \" features good guys , bad guys , lots of fighting , bloody violence , a leather-clad machine gun chick , gooey , self-healing bullet holes , scatological humor and a man-eating monster . \\nit not only appears to have been tailor made for a swarm of 12- and 13-year-old boys , it appears to have been made by them . \\nin a classic example of telling and not showing , \" spawn \" opens with a truckload of mumbo jumbo about forces of darkness , forces of light and how \" men are the ones w...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "396  it's difficult to expect much from a director whose greatest accomplishments to date are a handful of \" award-winning \" tv commercials , as is the case with bubble boy director blair hayes . \\nthat said , hayes's feature film debut lives up to expectations , coming off mainly as equal parts offensive and moronic . \\nbut occasionally , bubble boy transcends its substandard roots with glimmers of humor and scathing social commentary . \\nthose moments of intelligence are delivered mostly by the...   \n",
       "397  whether you like the beatles or not , nobody wants to see the bee gee's take on some of the fab four's best known songs . \\nwell , maybe that's not true . \\n . \\n . \\nmaybe you're curious , the way you have to look in your hanky after you blow your nose . \\nyou just have to know how bad bad can be . \\nif that's the case , rejoice , because it was twenty years ago today ( or so ) that sgt . \\npepper's lonely hearts club band was released ( unleashed ? ) to the world , and thanks to our modern...   \n",
       "\n",
       "     neg_prob  pos_prob  \n",
       "0       0.883     0.117  \n",
       "1       0.806     0.194  \n",
       "..        ...       ...  \n",
       "396     0.515     0.485  \n",
       "397     0.727     0.273  \n",
       "\n",
       "[138 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "neg INCORRECTLY CLASSIFIED as: pos\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>text</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>False</td>\n",
       "      <td>in the line of duty is the critically praised series of television movies dealing with the real-life incidents that claimed lives of law enforcement officers in usa . \\nthe twilight murders , another one from the series , is dealing with the case of gordon kahl ( played by rod steiger ) , old farmer from north dakota who would rather spend a year in prison than pay taxes to the despised u . s . government . \\nafter being released , he still refuses to pay taxes and the warrant is issued for ...</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>False</td>\n",
       "      <td>according to popular film opinion , a film's greatness is determined by time . \\ntake for example \" casablanca . \" \\ngreat film , even today . \\nit's still as powerful as it was when it came out and still as romantic and tragic . \\nanother example would be \" star wars , \" which had a very , very healthy box office gross despite the fact that we had all seen it about 3 billion times before . \\nbut as i rewatched \" independence day \" when it came out on video after being the number one hit of ...</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>False</td>\n",
       "      <td>spoiled rich kid kelley morse ( chris klein ) receives a new mercedes for a graduation present . \\nhe and his buddies take it for a joyride to a small nearby town , where he proceeds to torment the locals simply because he's rich and they're not . \\nhe ends up provoking jasper ( josh hartnett ) into a race and as a result , the local gas station and diner are destroyed when they crash into it . \\nkelley is sentenced to rebuild the diner , and has to live with jasper in a spare room over his ...</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>False</td>\n",
       "      <td>you think that these people only exist in the movies , but trust me , they're as real as life . \\ni once talked to a guy who thought the united states government was putting satellites into orbit which could fry an individual person's brain with microwaves . \\nthen i sat in a room full of people who believed that the government rigged state elections . \\ni even listened to a man who swore that nicotine was an additive that cigarette companies put in their products for the specific goal of ge...</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true predicted  correct  \\\n",
       "10   neg       pos    False   \n",
       "14   neg       pos    False   \n",
       "..   ...       ...      ...   \n",
       "388  neg       pos    False   \n",
       "398  neg       pos    False   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "10   in the line of duty is the critically praised series of television movies dealing with the real-life incidents that claimed lives of law enforcement officers in usa . \\nthe twilight murders , another one from the series , is dealing with the case of gordon kahl ( played by rod steiger ) , old farmer from north dakota who would rather spend a year in prison than pay taxes to the despised u . s . government . \\nafter being released , he still refuses to pay taxes and the warrant is issued for ...   \n",
       "14   according to popular film opinion , a film's greatness is determined by time . \\ntake for example \" casablanca . \" \\ngreat film , even today . \\nit's still as powerful as it was when it came out and still as romantic and tragic . \\nanother example would be \" star wars , \" which had a very , very healthy box office gross despite the fact that we had all seen it about 3 billion times before . \\nbut as i rewatched \" independence day \" when it came out on video after being the number one hit of ...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "388  spoiled rich kid kelley morse ( chris klein ) receives a new mercedes for a graduation present . \\nhe and his buddies take it for a joyride to a small nearby town , where he proceeds to torment the locals simply because he's rich and they're not . \\nhe ends up provoking jasper ( josh hartnett ) into a race and as a result , the local gas station and diner are destroyed when they crash into it . \\nkelley is sentenced to rebuild the diner , and has to live with jasper in a spare room over his ...   \n",
       "398  you think that these people only exist in the movies , but trust me , they're as real as life . \\ni once talked to a guy who thought the united states government was putting satellites into orbit which could fry an individual person's brain with microwaves . \\nthen i sat in a room full of people who believed that the government rigged state elections . \\ni even listened to a man who swore that nicotine was an additive that cigarette companies put in their products for the specific goal of ge...   \n",
       "\n",
       "     neg_prob  pos_prob  \n",
       "10      0.152     0.848  \n",
       "14      0.189     0.811  \n",
       "..        ...       ...  \n",
       "388     0.207     0.793  \n",
       "398     0.492     0.508  \n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pos INCORRECTLY CLASSIFIED as: neg\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>text</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>False</td>\n",
       "      <td>some of my friends who went to live in usa complain about one thing - that country is very different from the one depicted in hollywood movies . \\nthat is especially true for those who end up somewhere in that unexplored land between los angeles and new york where they find , to their big surprise , that the majority of people vote republican , go to church every sunday and usually don't tolerate liberal attitudes that are taken for granted in an average american film . \\nsuch rude awakening...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>False</td>\n",
       "      <td>\" the blair witch project \" was perhaps one of a kind , a unique film that played completely on its own merit , managing to scare even the most experienced horror fans out of their senses . \\nits success made a sequel inevitable , but this is not the sequel , i suspect , anyone much wanted . \\nafter the release of \" the blair witch project \" , tourists have practically invaded the small town of burkettsville , in order to get a glimpse of the blair witch . \\nlocals have turned this mass hys...</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>False</td>\n",
       "      <td>in the wake of the smashing success of \" rumble in the bronx , \" it's looking more and more likely that more jackie chan films will see american release . \\nrumor has it that one of these films will be drunken master ii . \\nthe version i have is a copy from the laserdisc ; it's widescreen and bilingually-subtitled , as are most hong kong films these days . \\navailability over here in the united states is very limited ; these films must either be purchased via pirates or sought out from asian...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>False</td>\n",
       "      <td>there exists a litany of differences between a successful action movie and a successful suspense movie . \\naction movies are typically devoid of plot other than a simple byline which can string together several explosive sequences , while suspense movies hinge on plot and subtlety and the ability to bring everything full-circle . \\nfor fans of both genres , however , realism is key . \\naction fans want to know that the weapons and methods their heroes are using are authentic , and suspense f...</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true predicted  correct  \\\n",
       "13   pos       neg    False   \n",
       "22   pos       neg    False   \n",
       "..   ...       ...      ...   \n",
       "393  pos       neg    False   \n",
       "394  pos       neg    False   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "13   some of my friends who went to live in usa complain about one thing - that country is very different from the one depicted in hollywood movies . \\nthat is especially true for those who end up somewhere in that unexplored land between los angeles and new york where they find , to their big surprise , that the majority of people vote republican , go to church every sunday and usually don't tolerate liberal attitudes that are taken for granted in an average american film . \\nsuch rude awakening...   \n",
       "22    \" the blair witch project \" was perhaps one of a kind , a unique film that played completely on its own merit , managing to scare even the most experienced horror fans out of their senses . \\nits success made a sequel inevitable , but this is not the sequel , i suspect , anyone much wanted . \\nafter the release of \" the blair witch project \" , tourists have practically invaded the small town of burkettsville , in order to get a glimpse of the blair witch . \\nlocals have turned this mass hys...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "393  in the wake of the smashing success of \" rumble in the bronx , \" it's looking more and more likely that more jackie chan films will see american release . \\nrumor has it that one of these films will be drunken master ii . \\nthe version i have is a copy from the laserdisc ; it's widescreen and bilingually-subtitled , as are most hong kong films these days . \\navailability over here in the united states is very limited ; these films must either be purchased via pirates or sought out from asian...   \n",
       "394  there exists a litany of differences between a successful action movie and a successful suspense movie . \\naction movies are typically devoid of plot other than a simple byline which can string together several explosive sequences , while suspense movies hinge on plot and subtlety and the ability to bring everything full-circle . \\nfor fans of both genres , however , realism is key . \\naction fans want to know that the weapons and methods their heroes are using are authentic , and suspense f...   \n",
       "\n",
       "     neg_prob  pos_prob  \n",
       "13      0.896     0.104  \n",
       "22      0.661     0.339  \n",
       "..        ...       ...  \n",
       "393     0.862     0.138  \n",
       "394     0.863     0.137  \n",
       "\n",
       "[57 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CORRECTLY CLASSIFIED: pos\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>text</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>the keen wisdom of an elderly bank robber , the naive ambitions of a sexy hospital nurse , and a partnership that blossoms between the two are the fine components that make up a modest , little caper adventure entitled `where the money is . ' \\nthe elderly bank robber is henry ( paul newman ) , a famous criminal that was only recently caught . \\nhe has pulled off dozens of successful heists and has probably stashed away a small fortune . \\nalways the shrewd thinker , he begins working on a p...</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>one of the sweetest tales to ever be made , it's a wonderful life isn't perfect , but its good natured charm and beautiful performances light up the screen with glorious results . \\nprobably the greatest \" feel-good \" film of all time , it's a wonderful life aims for the heart , and strikes with a golden arrow . \\non christmas eve , george bailey ( stewart ) is being prayed for by many in the small town of bedford falls . \\nyou see , george is in trouble , and he has always helped others who...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>if you had a chance to create a genetically perfect child , would you do it ? \\n \" gattaca \" is a film which presents a future where society has answered \" yes \" to this question , but then ponders if this was actually the right decision . \\n \" gattaca \" came out only a couple months following the first genetically engineered creature , the lovable dolly the sheep , and with this in mind , the film only becomes more frightening . \\nthe way the realm of genetics is heading , it may only take ...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>the postman delivers but not first class \\nthe postman a film review by michael redman copyright 1997 by michael redman \\n[warning : my opinion of this film is definitely in the minority of reviewers perhaps because it hits so many of my cinematic buttons : post-apocalypse stories , hope in a desperate situation , grassroots uprisings and kevin costner . \\neven worse , i thought that \" waterworld \" was watchable . \\nread the following with those particular grains of salt . ] \\nit's the year ...</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true predicted  correct  \\\n",
       "2    pos       pos     True   \n",
       "5    pos       pos     True   \n",
       "..   ...       ...      ...   \n",
       "395  pos       pos     True   \n",
       "399  pos       pos     True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "2    the keen wisdom of an elderly bank robber , the naive ambitions of a sexy hospital nurse , and a partnership that blossoms between the two are the fine components that make up a modest , little caper adventure entitled `where the money is . ' \\nthe elderly bank robber is henry ( paul newman ) , a famous criminal that was only recently caught . \\nhe has pulled off dozens of successful heists and has probably stashed away a small fortune . \\nalways the shrewd thinker , he begins working on a p...   \n",
       "5    one of the sweetest tales to ever be made , it's a wonderful life isn't perfect , but its good natured charm and beautiful performances light up the screen with glorious results . \\nprobably the greatest \" feel-good \" film of all time , it's a wonderful life aims for the heart , and strikes with a golden arrow . \\non christmas eve , george bailey ( stewart ) is being prayed for by many in the small town of bedford falls . \\nyou see , george is in trouble , and he has always helped others who...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "395  if you had a chance to create a genetically perfect child , would you do it ? \\n \" gattaca \" is a film which presents a future where society has answered \" yes \" to this question , but then ponders if this was actually the right decision . \\n \" gattaca \" came out only a couple months following the first genetically engineered creature , the lovable dolly the sheep , and with this in mind , the film only becomes more frightening . \\nthe way the realm of genetics is heading , it may only take ...   \n",
       "399  the postman delivers but not first class \\nthe postman a film review by michael redman copyright 1997 by michael redman \\n[warning : my opinion of this film is definitely in the minority of reviewers perhaps because it hits so many of my cinematic buttons : post-apocalypse stories , hope in a desperate situation , grassroots uprisings and kevin costner . \\neven worse , i thought that \" waterworld \" was watchable . \\nread the following with those particular grains of salt . ] \\nit's the year ...   \n",
       "\n",
       "     neg_prob  pos_prob  \n",
       "2       0.126     0.874  \n",
       "5       0.021     0.979  \n",
       "..        ...       ...  \n",
       "395     0.024     0.976  \n",
       "399     0.266     0.734  \n",
       "\n",
       "[143 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# adjust max rows\n",
    "pd.set_option('display.max_rows', 5) # show all rows\n",
    "\n",
    "# creating dataframe from y_predicted, y_test and the text\n",
    "predictions_df = pd.DataFrame(data = {'true': y_test, 'predicted': y_predicted})\n",
    "y_predicted_probs = pipeline.predict_proba(X_test)\n",
    "y_predicted_probs = np.round(y_predicted_probs, 3)\n",
    "columns = [f'{target_names[i]}_prob' for i in range(len(target_names))]\n",
    "predictions_df['predicted'] = predictions_df['predicted'].apply(lambda x: label_names[x])\n",
    "predictions_df['true'] = predictions_df['true'].apply(lambda x: label_names[x])\n",
    "predictions_df['correct'] = predictions_df['true'] == predictions_df['predicted']\n",
    "predictions_df['text'] = X_test\n",
    "predictions_df = pd.concat([predictions_df, pd.DataFrame(y_predicted_probs, columns=columns)], axis=1)\n",
    "\n",
    "# output a preview of docs for each cell of confusion matrix ...\n",
    "for true_target, target_name in enumerate(target_names):\n",
    "    for predicted_target, target_name in enumerate(target_names):\n",
    "        if true_target == predicted_target:\n",
    "            print(f'\\nCORRECTLY CLASSIFIED: {target_names[true_target]}')\n",
    "        else:\n",
    "            print(f'\\n{target_names[true_target]} INCORRECTLY CLASSIFIED as: {target_names[predicted_target]}')\n",
    "        print('=================================================================')\n",
    "\n",
    "        display(predictions_df[(predictions_df['true'] == target_names[true_target]) & (predictions_df['predicted'] == target_names[predicted_target])])\n",
    "\n",
    "pd.set_option('display.max_rows', 60) # setting back to the default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab796f98",
   "metadata": {},
   "source": [
    "### 4.4 Run inference on new (or old) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2120a",
   "metadata": {},
   "source": [
    "You can also run inference on new data (or any of the texts from training/validation) by changing the contents of the `texts` list below. This outputs a prediction, the probabilities of each class and the features present within the text that are used by the model to make its predictions. The numbers for each feature are the input to the final step of the pipeline. They may be scaled or transformed depending on the pipeline components you've chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615ca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0: \n",
      "It was excellent!\n",
      "\n",
      "\tPredicted class: neg\n",
      "\n",
      "\tProbability of class neg: 0.56\n",
      "\tProbability of class pos: 0.44\n",
      "\n",
      "\tFeatures:\n",
      "\n",
      "Text 1: \n",
      "This was a terrible movie!\n",
      "\n",
      "\tPredicted class: neg\n",
      "\n",
      "\tProbability of class neg: 0.58\n",
      "\tProbability of class pos: 0.42\n",
      "\n",
      "\tFeatures:\n",
      "\ttokens__movie: 1.00\n",
      "\n",
      "Text 2: \n",
      "This might not not be the best movie ever made, or it could be the best movie of no time.\n",
      "\n",
      "\tPredicted class: pos\n",
      "\n",
      "\tProbability of class neg: 0.47\n",
      "\tProbability of class pos: 0.53\n",
      "\n",
      "\tFeatures:\n",
      "\ttokens__best: 2.00\n",
      "\ttokens__ever: 1.00\n",
      "\ttokens__made: 1.00\n",
      "\ttokens__movie: 2.00\n",
      "\ttokens__time: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "texts = ['''\n",
    "It was excellent!\n",
    "''',\n",
    "\t\t'''\n",
    "This was a terrible movie!\n",
    "''',\n",
    "\t'''\n",
    "This might not not be the best movie ever made, or it could be the best movie of no time.\n",
    "''',\n",
    "]\n",
    "\n",
    "y_inference = pipeline.predict(texts)\n",
    "\n",
    "preprocessor = Pipeline(pipeline.steps[:-1])\n",
    "feature_names = preprocessor.named_steps['features'].get_feature_names_out()\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "\tprint(f\"Text {i}: {text}\")\n",
    "\t\n",
    "\tprint(f\"\\tPredicted class: {label_names[y_inference[i]]}\")\n",
    "\tprint()\n",
    "\n",
    "\ty_inference_proba = pipeline.predict_proba([text])\n",
    "\tfor i, prob in enumerate(y_inference_proba[0]):\n",
    "\t\tprint(f\"\\tProbability of class {target_names[i]}: {prob:.2f}\")\n",
    "\n",
    "\tprint()\n",
    "\tprint(\"\\tFeatures:\")\n",
    "\n",
    "\tembeddings = 0\n",
    "\tfrequencies = preprocessor.transform([text])\n",
    "\tif not isinstance(frequencies, np.ndarray):\n",
    "\t\tfrequencies = frequencies.toarray()\n",
    "\tfrequencies = frequencies[0].T\n",
    "\tfor j, freq in enumerate(frequencies):\n",
    "\t\tif feature_names[j].startswith('embeddings_'):\n",
    "\t\t\tembeddings += 1\n",
    "\t\telif freq > 0:\n",
    "\t\t\tprint(f\"\\t{feature_names[j]}: {freq:.2f}\")\n",
    "\tif embeddings > 0:\n",
    "\t\tprint(f\"\\tFeatures also include {embeddings} embedding dimensions\")\n",
    "\n",
    "\tprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850817eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
